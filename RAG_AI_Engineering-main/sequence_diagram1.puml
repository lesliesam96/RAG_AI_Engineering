@startuml
actor User
participant MainApp
participant Loader
participant DocumentLoader
participant TextSplitter
participant VectorStore
participant Embedding
participant Retriever
participant Agent
participant LangChainInterface

User -> MainApp: Upload file
MainApp -> Loader: load_file(file)
Loader -> DocumentLoader: load_and_split(text_splitter)
DocumentLoader -> TextSplitter: split_text(file content)
TextSplitter --> DocumentLoader: returns document chunks
DocumentLoader --> Loader: returns processed document
Loader --> MainApp: returns processed file data

MainApp -> VectorStore: vector_db_creation(file)
VectorStore -> Embedding: create_embeddings(document chunks)
Embedding --> VectorStore: returns embeddings
VectorStore -> Retriever: as_retriever()
Retriever --> VectorStore: returns retriever instance

User -> MainApp: Ask question
MainApp -> Agent: process question
Agent -> LangChainInterface: run(query)
LangChainInterface --> Agent: returns AI response
Agent --> MainApp: returns response
MainApp -> User: Display response

@enduml

Explanation of the Sequence Diagram:
User Interaction: The process begins when the user uploads a file to the MainApp.
File Processing: MainApp calls Loader to handle the file. Loader interacts with DocumentLoader, which uses TextSplitter to divide the document into chunks.
Embedding Creation: After processing the document, MainApp creates a vector store using VectorStore, which communicates with Embedding to generate embeddings from the document chunks.
Retriever Setup: VectorStore initializes a retriever (Retriever), allowing for document retrieval capabilities.
Question Processing: The user asks a question, which MainApp sends to Agent. Agent uses LangChainInterface to process the query, leveraging AI models to generate a response.
Response Display: The response generated by the AI is returned through the chain (LangChainInterface -> Agent -> MainApp) and displayed to the user.